{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from numpy import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from pandas.api.types import is_float_dtype\n",
    "from pandas.api.types import is_integer_dtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "import seaborn as sns\n",
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- Data Cleaning \n",
    "- Data Integration\n",
    "- Data Reduction\n",
    "- Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data\n",
    "Data asli dari Instansi Terkait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#memasukkan data\n",
    "df = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\BeasiswaBI.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status Beasiswa BI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA INTEGRATION\n",
    "Entity Identification Problem, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengganti nama record\n",
    "df=df.rename(columns={\n",
    "    'NR':'NR1',\n",
    "    'Unnamed: 2':'NR2',\n",
    "    'Unnamed: 3':'NR3',\n",
    "    'Unnamed: 4':'NR4',\n",
    "    'Unnamed: 5':'NR5',\n",
    "    'Unnamed: 6':'NR6',\n",
    "    'Unnamed: 7':'NR7',\n",
    "    'Unnamed: 8':'NR8',\n",
    "    'Unnamed: 9':'NR9',\n",
    "    'Unnamed: 10':'NR10',\n",
    "    'Unnamed: 11':'NR11'\n",
    "},inplace=False)\n",
    "header=list(df)\n",
    "\n",
    "#Menggeser value column\n",
    "for i in df.index:\n",
    "    j=1\n",
    "    if i!=0 :\n",
    "        while math.isnan(float(df.loc[i, header[j]])):\n",
    "            temp=df.loc[i, header[j]]\n",
    "            for k in range(0,11):\n",
    "                a=j+k\n",
    "                b=a+1\n",
    "                df.loc[i, header[a]]=df.loc[i, header[b]]\n",
    "            df.loc[i, header[11]]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menghapus baris pertama \n",
    "df=df.drop([0])\n",
    "\n",
    "#menghapus column\n",
    "df=df.reset_index(drop=True)\n",
    "for i in range(8,12):\n",
    "    if df[header[i]].isnull().sum():\n",
    "        del df[header[i]]\n",
    "        \n",
    "#Memindahkan Column\n",
    "x=df.loc[:,header[0]]\n",
    "del df['Status Beasiswa BI']\n",
    "df = df.apply(pd.to_numeric)\n",
    "df['Decision']=x\n",
    "# del df['NR1']\n",
    "# del df['NR2']\n",
    "# del df['NR3']\n",
    "# del df['NR4']\n",
    "# del df['NR5']\n",
    "# del df['NR6']\n",
    "# del df['NR7']\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "Handling Missing Value and Noisy Data\n",
    "- Dalam Handling Missing Value pada NR6 dan NR7 di gunakan rataan feature (Data Mining J.W. Han Chapter 3 Missing Values\n",
    "- Noisy Data ==> Setelah di cek ternyata ada 84 data yang outlier, Namun karena pada decision tree jumlah data mempengaruhi model. Serta jumah data yang akan dihapus cukup banyak yaitu 84/296 yang kira kira 30% maka tidak dilakukan penghapusan pada baris outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mengisi data yang kosong dengan  Rataan Feature\n",
    "#Handling missing value\n",
    "mean_NR6 = float(\"{:.1f}\".format(df.NR6.mean()))\n",
    "mean_NR7 = float(\"{:.1f}\".format(df.NR7.mean()))\n",
    "print(\"mean NR6 : \",mean_NR6)\n",
    "print(\"mean NR7 : \",mean_NR7)\n",
    "df=df.fillna({\"NR6\":mean_NR6,\"NR7\":mean_NR6})\n",
    "mean_NR6 = float(\"{:.1f}\".format(df.NR6.mean()))\n",
    "mean_NR7 = float(\"{:.1f}\".format(df.NR7.mean()))\n",
    "print(\"mean NR6 : \",mean_NR6)\n",
    "print(\"mean NR7 : \",mean_NR7)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect Outlier\n",
    "#Detection \n",
    "#IQR\n",
    "header=list(df)\n",
    "for i in range(12):\n",
    "    print(\"Header : {name}\".format(name=header[i]))\n",
    "    Q1 = np.percentile(df[header[i]], 25,\n",
    "                       interpolation = 'midpoint')\n",
    "    Q3 = np.percentile(df[header[i]], 75,\n",
    "                       interpolation = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    print(\"Old Shape: \", df.shape)\n",
    "\n",
    "    # Upper bound\n",
    "    upper = np.where(df[header[i]] >= (Q3+1.5*IQR))\n",
    "    # Lower bound\n",
    "    lower = np.where(df[header[i]] <= (Q1-1.5*IQR))\n",
    "\n",
    "    ''' Removing the Outliers '''\n",
    "    sns.boxplot(df[header[i]])\n",
    "    plt.show()\n",
    "    df.drop(upper[0], inplace = True)\n",
    "    df.drop(lower[0], inplace = True)\n",
    "    df=df.reset_index(drop=True)\n",
    "    print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA REDUCTION\n",
    "Tidak dilakukan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyesuaikan Type Data dan Membagi data menjadi 3 (train, validasi, dan test)\n",
    "header=list(df)\n",
    "for i in range (8,12,1):\n",
    "    df[header[i]]=df[header[i]].astype('int')\n",
    "\n",
    "# x=df.iloc[:,0:7]\n",
    "# x=x.to_numpy()\n",
    "# est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "# est.fit(x)\n",
    "# Xt = est.transform(x)\n",
    "# df.iloc[:,0:7]=Xt\n",
    "\n",
    "# x=df.iloc[:,7:8]\n",
    "# x=x.to_numpy()\n",
    "# est = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')\n",
    "# est.fit(x)\n",
    "# Xt = est.transform(x)\n",
    "# df.iloc[:,7:8]=Xt\n",
    "\n",
    "# x=df.iloc[:,8:9]\n",
    "# x=x.to_numpy()\n",
    "# est = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')\n",
    "# est.fit(x)\n",
    "# Xt = est.transform(x)\n",
    "# df.iloc[:,8:9]=Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entropy(yes,no,jumlah):\n",
    "#     if yes==0:\n",
    "#         return 0\n",
    "#     elif no==0:\n",
    "#         return 0\n",
    "#     return (-(((yes/jumlah)*(math.log2(yes/jumlah)))+((no/jumlah)*(math.log2(no/jumlah)))))\n",
    "# def attrGainTertinggi(entrophyKeseluruhan,attr):\n",
    "#     # Membagi atribut menjadi 3 group yang jumlahnya dalam satu grup sama\n",
    "#     attr['Bins']=pd.qcut(attr[attr.columns[0]],q=3)\n",
    "#     mean = attr.groupby('Bins')[attr.columns[0]].transform('mean').unique()\n",
    "#     Max=0\n",
    "#     for i in mean:\n",
    "#         Gain=entrophyKeseluruhan\n",
    "#         a1=attr[(attr[attr.columns[0]] <= i) & (attr[attr.columns[1]] == 'Iya')][attr.columns[1]].count()\n",
    "#         a2=attr[(attr[attr.columns[0]] <= i) & (attr[attr.columns[1]] == 'Tidak')][attr.columns[1]].count()\n",
    "#         a3=a1+a2\n",
    "#         aJumlah=attr[attr[attr.columns[0]] <= i][attr.columns[1]].count()\n",
    "#         b1=attr[(attr[attr.columns[0]] > i) & (attr[attr.columns[1]] == 'Iya')][attr.columns[1]].count()\n",
    "#         b2=attr[(attr[attr.columns[0]] > i) & (attr[attr.columns[1]] == 'Tidak')][attr.columns[1]].count()\n",
    "#         b3=b1+b2\n",
    "#         bJumlah=attr[attr[attr.columns[0]] > i][attr.columns[1]].count()\n",
    "#         cJumlah=aJumlah+bJumlah\n",
    "#         E1=entropy(a1,a2,aJumlah)\n",
    "#         E2=entropy(b1,b2,bJumlah)\n",
    "#         Gain=Gain-((a3/cJumlah*E1)+(b3/cJumlah*E2))\n",
    "#         if Gain>Max:\n",
    "#             Max=i\n",
    "#     return Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes=df[df.Decision == \"Iya\"][\"Decision\"].count()\n",
    "# no=df[df.Decision == \"Iya\"][\"Decision\"].count()\n",
    "# jumlah=df[\"Decision\"].count()\n",
    "# Entrophy=entropy(yes,no,jumlah)\n",
    "\n",
    "# #index 0 = NR1 - Index 7 = IP\n",
    "# for i in range(8,9,1):\n",
    "#     data=df.loc[0:,[df.columns[i],'Decision']].sort_values(by=[df.columns[i]])\n",
    "#     ### CEK v di column, float ==> Diskret, Penghasilan ortu Diskret 9.\n",
    "#     if(is_float_dtype(df[df.columns[i]])):\n",
    "#         Max=attrGainTertinggi(Entrophy,data)\n",
    "#         data=data.sort_index()\n",
    "#         ##Ganti data/Pendiskritan\n",
    "#         for j,row in data.iterrows():\n",
    "#             if(row[0]<=Max):\n",
    "#                 data.loc[j,[data.columns[0]]]='<='+str(Max)\n",
    "#             else:\n",
    "#                 data.loc[j,[data.columns[0]]]='>'+str(Max)        \n",
    "#     elif (is_integer_dtype(df[df.columns[i]])):\n",
    "#         kategori = ['Golongan I', \n",
    "#                     'Golongan II', \n",
    "#                     'Golongan III',\n",
    "#                     'Golongan IV', \n",
    "#                     'Golongan V', \n",
    "#                     'Golongan VI',\n",
    "#                     'Golongan VII', \n",
    "#                     'Golongan VIII', \n",
    "#                     'Golongan IX']\n",
    "#         data=data.sort_index()\n",
    "#         data[data.columns[0]] = pd.cut(data[data.columns[0]], bins=9, labels=kategori)\n",
    "#     df.iloc[0:,[i]]=data.iloc[0:,[0]]  \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8,9,1):\n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     le.fit(df[df.columns[i]])\n",
    "#     df[df.columns[i]]=le.transform(df[df.columns[i]])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DATA SAMPLE 20 data Iya, 10 data tidak\n",
    "# df1=df.head(148).sample(n=15)\n",
    "# df2=df.tail(148).sample(n=15)\n",
    "# df=df1\n",
    "# df=df.append(df2,ignore_index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Data 70 train, 15 Validation, dan 15 test\n",
    "df_train, df_validation, df_test=np.split(df.sample(frac=1),[int(0.7*len(df)),int(0.85*len(df))])\n",
    "# \n",
    "outcome_train = df_train.Decision.tolist()\n",
    "outcome_validation=df_validation.Decision.tolist()\n",
    "outcome_test = df_test.Decision.tolist()\n",
    "\n",
    "train_data_remove = df_train.drop(columns = \"Decision\")\n",
    "validation_data_remove = df_validation.drop(columns = \"Decision\")\n",
    "test_data_remove = df_test.drop(columns = \"Decision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writerTrain = pd.ExcelWriter('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTrain.xlsx')\n",
    "# writerValidation = pd.ExcelWriter('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataValidation.xlsx')\n",
    "# writerTest = pd.ExcelWriter('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTest.xlsx')\n",
    "\n",
    "# # write dataframe to excel\n",
    "# df_train.to_excel(writerTrain)\n",
    "# df_validation.to_excel(writerValidation)\n",
    "# df_test.to_excel(writerTest)\n",
    "\n",
    "# # save the excel\n",
    "# writerTrain.save()\n",
    "# writerValidation.save()\n",
    "# writerTest.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    "Data yang sudah dilakukan Proses Data Preparation dan disimpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTrain.xlsx')\n",
    "# df_validation = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataValidation.xlsx')\n",
    "# df_test = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTest.xlsx')\n",
    "\n",
    "# df_train = df_train.set_index(df_train.columns[0])\n",
    "# df_validation = df_validation.set_index(df_validation.columns[0])\n",
    "# df_test = df_test.set_index(df_test.columns[0])\n",
    "\n",
    "# outcome_train = df_train.Decision.tolist()\n",
    "# outcome_validation=df_validation.Decision.tolist()\n",
    "# outcome_test = df_test.Decision.tolist()\n",
    "\n",
    "# train_data_remove = df_train.drop(columns = \"Decision\")\n",
    "# validation_data_remove = df_validation.drop(columns = \"Decision\")\n",
    "# test_data_remove = df_test.drop(columns = \"Decision\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Sampling Data\n",
    "Data yang sudah dilakukan Proses Data Preparation, Sample (30 data) dan disimpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataTrain.xlsx')\n",
    "# df_validation = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataValidation.xlsx')\n",
    "# df_test = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataTest.xlsx')\n",
    "\n",
    "# df_train = df_train.set_index(df_train.columns[0])\n",
    "# df_validation = df_validation.set_index(df_validation.columns[0])\n",
    "# df_test = df_test.set_index(df_test.columns[0])\n",
    "\n",
    "# outcome_train = df_train.Decision.tolist()\n",
    "# outcome_validation=df_validation.Decision.tolist()\n",
    "# outcome_test = df_test.Decision.tolist()\n",
    "\n",
    "# train_data_remove = df_train.drop(columns = \"Decision\")\n",
    "# validation_data_remove = df_validation.drop(columns = \"Decision\")\n",
    "# test_data_remove = df_test.drop(columns = \"Decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['Decision']==\"Iya\"].count()[12],\n",
    "df_train[df_train['Decision']==\"Tidak\"].count()[12],\n",
    "df_validation[df_validation['Decision']==\"Iya\"].count()[12],\n",
    "df_validation[df_validation['Decision']==\"Tidak\"].count()[12],\n",
    "df_test[df_test['Decision']==\"Iya\"].count()[12],\n",
    "df_test[df_test['Decision']==\"Tidak\"].count()[12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemodelan\n",
    "with C4.5 Algorithm dan REP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLeaves(tree,node_id):\n",
    "#     print(tree.tree_.children_left[node_id], tree.tree_.children_right[node_id])\n",
    "    if (tree.tree_.children_left[node_id] == tree.tree_.children_right[node_id]):\n",
    "        return True\n",
    "    return False\n",
    "def canPrune(tree,node_id):\n",
    "    kiri=isLeaves(tree,tree.tree_.children_left[node_id])\n",
    "    kanan=isLeaves(tree,tree.tree_.children_right[node_id])\n",
    "#     print(kiri,kanan,not(isLeaves(tree,node_id)))\n",
    "#     print((kiri & kanan) & (not(isLeaves(tree,node_id))))\n",
    "    if ((kiri & kanan) & (not(isLeaves(tree,node_id)))):\n",
    "        return True\n",
    "    return False\n",
    "def makeGraph(clf,iterasi,realData):\n",
    "    if realData:\n",
    "        stringSampleData=\"\"        \n",
    "    stringSampleData=\"Sample \"\n",
    "    \n",
    "    dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                    feature_names=header[0:12],\n",
    "                                    class_names=['Iya','Tidak'],\n",
    "                                    filled=True,rounded=True,\n",
    "                                    special_characters=True) \n",
    "\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render('{stringTambahan}Tree After Pruning at - {iterasi}'.format(stringTambahan=stringSampleData,iterasi=iterasi),view=True)\n",
    "    # graph\n",
    "def summarize(maxDepth,feature,feature_importance):\n",
    "    print('Kedalaman Tree yang terbentuk : ',maxDepth)\n",
    "    Feature_importance=pd.DataFrame({\n",
    "                            'Feature_importance':feature_importance\n",
    "                        },index=feature).sort_values(by=[\"Feature_importance\"],ascending=False)\n",
    "#     Feature_importance=Feature_importance.reset_index(drop=True)\n",
    "    print(Feature_importance.index)\n",
    "    print(Feature_importance)\n",
    "    Feature_importance.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5 | Data Keseluruhan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DATA INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTrain.xlsx')\n",
    "df_validation = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataValidation.xlsx')\n",
    "df_test = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\DataTest.xlsx')\n",
    "\n",
    "df_train = df_train.set_index(df_train.columns[0])\n",
    "df_validation = df_validation.set_index(df_validation.columns[0])\n",
    "df_test = df_test.set_index(df_test.columns[0])\n",
    "\n",
    "outcome_train = df_train.Decision.tolist()\n",
    "outcome_validation=df_validation.Decision.tolist()\n",
    "outcome_test = df_test.Decision.tolist()\n",
    "\n",
    "train_data_remove = df_train.drop(columns = \"Decision\")\n",
    "validation_data_remove = df_validation.drop(columns = \"Decision\")\n",
    "test_data_remove = df_test.drop(columns = \"Decision\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pemodelan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "clf = clf.fit(train_data_remove, outcome_train)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=header[0:12],\n",
    "                                class_names=['Iya','Tidak'],\n",
    "                                filled=True,rounded=True,\n",
    "                                special_characters=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = 'png'\n",
    "graph.render('Tree Without Pruning',view=True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = clf.predict(train_data_remove).tolist()\n",
    "TrainAccuracy = sklearn.metrics.accuracy_score(outcome_train, train_array)\n",
    "print('C4.5 Testing accuracy with Data Train: ',TrainAccuracy)\n",
    "print('C4.5 Testing Error Rate with Data Train: ',1-TrainAccuracy)\n",
    "test_array1 = clf.predict(test_data_remove).tolist()\n",
    "\n",
    "oldModelProp=[clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_]\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array1 = clf.predict(test_data_remove).tolist()\n",
    "CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array1)\n",
    "print('C4.5 tanpa REP Testing Accuracy dengan Data Test: ',CTestAccuracy)\n",
    "print('C4.5 tanpa REP Testing Error Rate dengan Data Test: ',1-CTestAccuracy)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)\n",
    "# akurasidenganaoutlier.append([CTestAccuracy,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Iya','Tidak']\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix testing model with data test, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix testing model with data test\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, test_data_remove, outcome_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5 | Data Keseluruhan | REP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pemangkasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes=clf.tree_.node_count\n",
    "node_id=n_nodes-1\n",
    "newClf=clf\n",
    "feature = clf.tree_.feature\n",
    "ErrorRate=0\n",
    "newErrorRate=0\n",
    "startNode=node_id\n",
    "pruned=1\n",
    "while (node_id>-1):\n",
    "    print(node_id,pruned)\n",
    "    #Cek Accurasi dengan data validation di sebelum Pruning\n",
    "    validation_array1 = clf.predict(validation_data_remove).tolist()\n",
    "    validationAccuracy1 = sklearn.metrics.accuracy_score(outcome_validation, validation_array1)\n",
    "    ErrorRate = 1-validationAccuracy1\n",
    "    \n",
    "    newFeature = newClf.tree_.feature\n",
    "    if(canPrune(newClf,node_id)):#????\n",
    "        print('Pohon tanpa pemangkasan: ')\n",
    "        tree.plot_tree(clf)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Node {node} akan dipruning\".format(node=header[feature[node_id]]))\n",
    "        newNode_id=node_id\n",
    "        stack.append((newClf.tree_.children_left[node_id], newClf.tree_.children_right[node_id]))\n",
    "        newClf.tree_.children_left[node_id]=TREE_LEAF\n",
    "        newClf.tree_.children_right[node_id]=TREE_LEAF\n",
    "\n",
    "        print('Pohon dengan pemangkasan: ')\n",
    "        tree.plot_tree(newClf)\n",
    "        plt.show()\n",
    "        makeGraph(clf,pruned,True)\n",
    "        pruned+=1\n",
    "    \n",
    "    #Cek Accurasi dengan data validation setelah Pruning\n",
    "    validation_array2 = newClf.predict(validation_data_remove).tolist()\n",
    "    validationAccuracy2 = sklearn.metrics.accuracy_score(outcome_validation, validation_array2)    \n",
    "    newErrorRate = 1-validationAccuracy2\n",
    "    \n",
    "    print('Perbandingan validasi Score Lama vs Baru: ',validationAccuracy1,validationAccuracy2)\n",
    "    print('Perbandingan ErrorRate Lama vs Baru: ',ErrorRate,newErrorRate)\n",
    "    \n",
    "    if(newErrorRate>ErrorRate):\n",
    "        newClf.tree_.children_left[newNode_id], newClf.tree_.children_right[newNode_id]=stack.pop()\n",
    "        pruned-=1\n",
    "    else:\n",
    "        clf=newClf\n",
    "#         if(ErrorRate != newErrorRate):\n",
    "#             startNode=node_id\n",
    "    node_id-=1\n",
    "    #break ketika node_id==startNode\n",
    "#     if(startNode == node_id):\n",
    "#         break\n",
    "#     #ngembaliin node ke awal => start node di awal =>\n",
    "#     if(node_id == -1):\n",
    "#         startNode=-1\n",
    "#         node_id=n_nodes-1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_array1 = clf.predict(validation_data_remove).tolist()\n",
    "validationAccuracy1 = sklearn.metrics.accuracy_score(outcome_validation, validation_array1)\n",
    "ErrorRate = 1-validationAccuracy1\n",
    "print('C4.5 Testing Accuracy With Data Validation: ',validationAccuracy1)\n",
    "print('C4.5 Testing Error Rate With Data Validation: ',ErrorRate)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_array1 = clf.predict(test_data_remove).tolist()\n",
    "# CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array1)\n",
    "# print('C4.5 tanpa REP Testing Accuracy dengan Data Test: ',CTestAccuracy)\n",
    "# print('C4.5 tanpa REP Testing Error Rate dengan Data Test: ',1-CTestAccuracy)\n",
    "# summarize(oldModelProp[0],oldModelProp[1],oldModelProp[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array2 = clf.predict(test_data_remove).tolist()\n",
    "CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array2)\n",
    "print('C4.5 dengan REP Testing Accuracy dengan Data Test: ',CTestAccuracy)\n",
    "print('C4.5 dengan REP Testing Error Rate dengan Data Test: ',1-CTestAccuracy)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Iya','Tidak']\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix testing model with data test, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix testing model with data test\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, test_data_remove, outcome_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# akurasidenganaoutlier[iterasi][1]=CTestAccuracy\n",
    "# df_akurasidenganaoutlier= pd.DataFrame(akurasidenganaoutlier, columns =['Tanpa REP', 'Dengan REP'])\n",
    "# df_akurasidenganaoutlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5 | DATA SAMPLE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataTrain.xlsx')\n",
    "df_validation = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataValidation.xlsx')\n",
    "df_test = pd.read_excel ('D:\\MyProject\\RekomendasiBeasiswa\\Data\\DoneDataPreparation\\SampleDataTest.xlsx')\n",
    "\n",
    "df_train = df_train.set_index(df_train.columns[0])\n",
    "df_validation = df_validation.set_index(df_validation.columns[0])\n",
    "df_test = df_test.set_index(df_test.columns[0])\n",
    "\n",
    "outcome_train = df_train.Decision.tolist()\n",
    "outcome_validation=df_validation.Decision.tolist()\n",
    "outcome_test = df_test.Decision.tolist()\n",
    "\n",
    "train_data_remove = df_train.drop(columns = \"Decision\")\n",
    "validation_data_remove = df_validation.drop(columns = \"Decision\")\n",
    "test_data_remove = df_test.drop(columns = \"Decision\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pemodelan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.tree.DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "clf = clf.fit(train_data_remove, outcome_train)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=header[0:12],\n",
    "                                class_names=['Iya','Tidak'],\n",
    "                                filled=True,rounded=True,\n",
    "                                special_characters=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = 'png'\n",
    "graph.render('Sample Tree Without Pruning',view=True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = clf.predict(train_data_remove).tolist()\n",
    "TrainAccuracy = sklearn.metrics.accuracy_score(outcome_train, train_array)\n",
    "print('C4.5 Testing accuracy with Sample Data Train: ',TrainAccuracy)\n",
    "print('C4.5 Testing Error Rate with Sample Data Train: ',1-TrainAccuracy)\n",
    "test_array1 = clf.predict(test_data_remove).tolist()\n",
    "\n",
    "oldModelProp=[clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_]\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array1 = clf.predict(test_data_remove).tolist()\n",
    "CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array1)\n",
    "print('C4.5 tanpa REP Testing Accuracy dengan Sample Data Test: ',CTestAccuracy)\n",
    "print('C4.5 tanpa REP Testing Error Rate dengan Sample Data Test: ',1-CTestAccuracy)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)\n",
    "# akurasidenganaoutlier.append([CTestAccuracy,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Iya','Tidak']\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix testing model with data test, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix testing model with data test\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, test_data_remove, outcome_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5 | DATA SAMPLE | REP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pemangkasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes=clf.tree_.node_count\n",
    "node_id=n_nodes-1\n",
    "newClf=clf\n",
    "feature = clf.tree_.feature\n",
    "ErrorRate=0\n",
    "newErrorRate=0\n",
    "startNode=node_id\n",
    "pruned=1\n",
    "while (node_id>-1):\n",
    "    print(node_id,pruned)\n",
    "    #Cek Accurasi dengan data validation di sebelum Pruning\n",
    "    validation_array1 = clf.predict(validation_data_remove).tolist()\n",
    "    validationAccuracy1 = sklearn.metrics.accuracy_score(outcome_validation, validation_array1)\n",
    "    ErrorRate = 1-validationAccuracy1\n",
    "    \n",
    "    newFeature = newClf.tree_.feature\n",
    "    if(canPrune(newClf,node_id)):#????\n",
    "        print('Pohon tanpa pemangkasan: ')\n",
    "        tree.plot_tree(clf)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Node {node} akan dipruning\".format(node=header[feature[node_id]]))\n",
    "        newNode_id=node_id\n",
    "        stack.append((newClf.tree_.children_left[node_id], newClf.tree_.children_right[node_id]))\n",
    "        newClf.tree_.children_left[node_id]=TREE_LEAF\n",
    "        newClf.tree_.children_right[node_id]=TREE_LEAF\n",
    "\n",
    "        print('Pohon dengan pemangkasan: ')\n",
    "        tree.plot_tree(newClf)\n",
    "        plt.show()\n",
    "        makeGraph(clf,pruned,False)\n",
    "        pruned+=1\n",
    "    \n",
    "    #Cek Accurasi dengan data validation setelah Pruning\n",
    "    validation_array2 = newClf.predict(validation_data_remove).tolist()\n",
    "    validationAccuracy2 = sklearn.metrics.accuracy_score(outcome_validation, validation_array2)    \n",
    "    newErrorRate = 1-validationAccuracy2\n",
    "    \n",
    "    print('Perbandingan validasi Score Lama vs Baru: ',validationAccuracy1,validationAccuracy2)\n",
    "    print('Perbandingan ErrorRate Lama vs Baru: ',ErrorRate,newErrorRate)\n",
    "    \n",
    "    if(newErrorRate>ErrorRate):\n",
    "        newClf.tree_.children_left[newNode_id], newClf.tree_.children_right[newNode_id]=stack.pop()\n",
    "        pruned-=1\n",
    "    else:\n",
    "        clf=newClf\n",
    "#         if(ErrorRate != newErrorRate):\n",
    "#             startNode=node_id\n",
    "    node_id-=1\n",
    "    #break ketika node_id==startNode\n",
    "#     if(startNode == node_id):\n",
    "#         break\n",
    "#     #ngembaliin node ke awal => start node di awal =>\n",
    "#     if(node_id == -1):\n",
    "#         startNode=-1\n",
    "#         node_id=n_nodes-1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_array1 = clf.predict(validation_data_remove).tolist()\n",
    "validationAccuracy1 = sklearn.metrics.accuracy_score(outcome_validation, validation_array1)\n",
    "ErrorRate = 1-validationAccuracy1\n",
    "print('C4.5 Testing Accuracy With Sample Data Validation: ',validationAccuracy1)\n",
    "print('C4.5 Testing Error Rate With Sample Data Validation: ',ErrorRate)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_array1 = clf.predict(test_data_remove).tolist()\n",
    "# CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array1)\n",
    "# print('C4.5 tanpa REP Testing Accuracy dengan Data Test: ',CTestAccuracy)\n",
    "# print('C4.5 tanpa REP Testing Error Rate dengan Data Test: ',1-CTestAccuracy)\n",
    "# summarize(oldModelProp[0],oldModelProp[1],oldModelProp[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array2 = clf.predict(test_data_remove).tolist()\n",
    "CTestAccuracy = sklearn.metrics.accuracy_score(outcome_test, test_array2)\n",
    "print('C4.5 dengan REP Testing Accuracy dengan Sample Data Test: ',CTestAccuracy)\n",
    "print('C4.5 dengan REP Testing Error Rate dengan Sample Data Test: ',1-CTestAccuracy)\n",
    "summarize(clf.tree_.max_depth,list(train_data_remove),clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Iya','Tidak']\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix testing model with data test, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix testing model with data test\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, test_data_remove, outcome_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELESAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_nodes = clf.tree_.node_count\n",
    "# children_left = clf.tree_.children_left\n",
    "# children_right = clf.tree_.children_right\n",
    "# feature = clf.tree_.feature\n",
    "# threshold = clf.tree_.threshold\n",
    "\n",
    "# print('Banyaknya Node : ',n_nodes)\n",
    "# print('Banyaknya Child Kiri :', children_left)\n",
    "# print('Banyaknya Child Kanan :', children_right)\n",
    "# print('Feature : ',feature)\n",
    "# print('Threshold : ',threshold)\n",
    "# node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "# is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "# stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "# while len(stack) > 0:\n",
    "#     # `pop` ensures each node is only visited once\n",
    "#     print(stack)\n",
    "#     node_id, depth = stack.pop()\n",
    "#     node_depth[node_id] = depth\n",
    "\n",
    "#     # If the left and right child of a node is not the same we have a split\n",
    "#     # node\n",
    "#     is_split_node = children_left[node_id] != children_right[node_id]\n",
    "#     # If a split node, append left and right children and depth to `stack`\n",
    "#     # so we can loop through them\n",
    "#     if is_split_node:\n",
    "#         stack.append((children_left[node_id], depth + 1))\n",
    "#         stack.append((children_right[node_id], depth + 1))\n",
    "#     else:\n",
    "#         is_leaves[node_id] = True\n",
    "\n",
    "# print(\"The binary tree structure has {n} nodes and has \"\n",
    "#       \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "# for i in range(n_nodes):\n",
    "#     if is_leaves[i]:\n",
    "#         print(\"{space}node={node} is a leaf node.\".format(\n",
    "#             space=node_depth[i] * \"\\t\", node=i))\n",
    "#     else:\n",
    "#         print(\"{space}node={node} is a split node: \"\n",
    "#               \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "#               \"else to node {right}.\".format(\n",
    "#                   space=node_depth[i] * \"\\t\",\n",
    "#                   node=i,\n",
    "#                   left=children_left[i],\n",
    "#                   feature=feature[i],\n",
    "#                   threshold=threshold[i],\n",
    "#                   right=children_right[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
